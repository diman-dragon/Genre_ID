{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество изображений в тренировочном наборе: 6194\n",
      "Количество изображений в тестовом наборе: 1554\n"
     ]
    }
   ],
   "source": [
    "# Предобработка данных\n",
    "# Функция для чтения и предобработки изображений\n",
    "def preprocess_image(image_path, target_size=(300, 300)):\n",
    "    # Загрузка изображения\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    # Преобразование изображения в массив numpy\n",
    "    img_array = img_to_array(img)\n",
    "    # Нормализация значений пикселей к диапазону [0, 1]\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array\n",
    "\n",
    "# Используем функцию preprocess_image для предобработки всех изображений из датасета\n",
    "def preprocess_images(dataframe):\n",
    "    processed_images = []\n",
    "    for image_path in dataframe['image_path']:\n",
    "        processed_image = preprocess_image(image_path)\n",
    "        processed_images.append(processed_image)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "# Применяем функцию предобработки к тренировочным и тестовым данным\n",
    "train_images = preprocess_images(train_data)\n",
    "test_images = preprocess_images(test_data)\n",
    "\n",
    "# Получаем количество изображений в тренировочном и тестовом наборах\n",
    "num_train_images = train_images.shape[0]\n",
    "num_test_images = test_images.shape[0]\n",
    "\n",
    "print(\"Количество изображений в тренировочном наборе:\", num_train_images)\n",
    "print(\"Количество изображений в тестовом наборе:\", num_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6194 validated image filenames belonging to 10 classes.\n",
      "Found 1554 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Создаем экземпляры ImageDataGenerator для аугментации тренировочных и тестовых изображений\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,            # Перенормировка значений пикселей\n",
    "    rotation_range=20,         # Угол поворота (в градусах)\n",
    "    width_shift_range=0.2,     # Сдвиг по ширине\n",
    "    height_shift_range=0.2,    # Сдвиг по высоте\n",
    "    shear_range=0.2,           # Направление сдвига\n",
    "    zoom_range=0.2,            # Масштабирование\n",
    "    horizontal_flip=True,      # Отражение по горизонтали\n",
    "    fill_mode='nearest'        # Заполнение пикселей за пределами границ изображения\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Только перенормировка для тестовых данных\n",
    "\n",
    "# Создаем генераторы данных для тренировочного и тестового наборов\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    x_col='image_path',            # Имя столбца с путями к изображениям\n",
    "    y_col='label',                 # Имя столбца с метками классов\n",
    "    target_size=(150, 150),        # Размер изображений (высота, ширина)\n",
    "    batch_size=32,                 # Размер пакета данных\n",
    "    class_mode='categorical'       # Режим классификации (категориальная классификация)\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_data,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных классов: 10\n"
     ]
    }
   ],
   "source": [
    "# Получаем словарь классов и их индексов\n",
    "class_indices = train_generator.class_indices\n",
    "\n",
    "# Получаем количество уникальных классов\n",
    "num_classes = len(class_indices)\n",
    "\n",
    "# Выводим количество уникальных классов\n",
    "print(\"Количество уникальных классов:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14488\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "\n",
    "# Добавляем сверточные слои с пулингом\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Добавляем слой для сглаживания данных перед подачей на полносвязные слои\n",
    "model.add(Flatten())\n",
    "\n",
    "# Добавляем полносвязные слои\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Добавляем слой Dropout для уменьшения переобучения\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Выходной слой с softmax для классификации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14488\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 504ms/step - accuracy: 0.1966 - loss: 2.2036 - val_accuracy: 0.2709 - val_loss: 2.1143\n",
      "Epoch 2/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 489ms/step - accuracy: 0.2767 - loss: 2.0839 - val_accuracy: 0.3211 - val_loss: 2.0228\n",
      "Epoch 4/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 483ms/step - accuracy: 0.3107 - loss: 2.0223 - val_accuracy: 0.3301 - val_loss: 1.9737\n",
      "Epoch 6/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 474ms/step - accuracy: 0.3233 - loss: 1.9810 - val_accuracy: 0.3378 - val_loss: 1.9240\n",
      "Epoch 8/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 483ms/step - accuracy: 0.3174 - loss: 1.9796 - val_accuracy: 0.3372 - val_loss: 1.9235\n",
      "Epoch 10/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 - 7s - 133ms/step - accuracy: 0.3372 - loss: 1.9235\n",
      "Потери на тестовых данных: 1.923471212387085\n",
      "Точность на тестовых данных: 0.3371943235397339\n"
     ]
    }
   ],
   "source": [
    "# Оценка производительности модели на тестовых данных:\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=2)\n",
    "print(f'Потери на тестовых данных: {test_loss}')\n",
    "print(f'Точность на тестовых данных: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
