{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6194 validated image filenames belonging to 10 classes.\n",
      "Found 1554 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Создаем экземпляры ImageDataGenerator для аугментации тренировочных и тестовых изображений\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,            # Перенормировка значений пикселей\n",
    "    rotation_range=20,         # Угол поворота (в градусах)\n",
    "    width_shift_range=0.2,     # Сдвиг по ширине\n",
    "    height_shift_range=0.2,    # Сдвиг по высоте\n",
    "    shear_range=0.2,           # Направление сдвига\n",
    "    zoom_range=0.2,            # Масштабирование\n",
    "    horizontal_flip=True,      # Отражение по горизонтали\n",
    "    fill_mode='nearest'        # Заполнение пикселей за пределами границ изображения\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,            # Перенормировка значений пикселей\n",
    "    rotation_range=20,         # Угол поворота (в градусах)\n",
    "    width_shift_range=0.2,     # Сдвиг по ширине\n",
    "    height_shift_range=0.2,    # Сдвиг по высоте\n",
    "    shear_range=0.2,           # Направление сдвига\n",
    "    zoom_range=0.2,            # Масштабирование\n",
    "    horizontal_flip=True,      # Отражение по горизонтали\n",
    "    fill_mode='nearest'        # Заполнение пикселей за пределами границ изображения\n",
    "    )  \n",
    "\n",
    "# Создаем генераторы данных для тренировочного и тестового наборов\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_data,\n",
    "    x_col='image_path',            # Имя столбца с путями к изображениям\n",
    "    y_col='label',                 # Имя столбца с метками классов\n",
    "    target_size=(300, 300),        # Размер изображений (высота, ширина)\n",
    "    batch_size=32,                 # Размер пакета данных\n",
    "    class_mode='categorical'       # Режим классификации (категориальная классификация)\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_data,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество уникальных классов: 10\n"
     ]
    }
   ],
   "source": [
    "# Получаем словарь классов и их индексов\n",
    "class_indices = train_generator.class_indices\n",
    "\n",
    "# Получаем количество уникальных классов\n",
    "num_classes = len(class_indices)\n",
    "\n",
    "# Выводим количество уникальных классов\n",
    "print(\"Количество уникальных классов:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последовательная модель нейронной сети с использованием библиотеки Keras/TensorFlow.  \n",
    "Давайте разберем каждый слой:  \n",
    " \n",
    "Свёрточный слой (Conv2D):  \n",
    "Количество фильтров: 32  \n",
    "Размер ядра: (3, 3)  \n",
    "Функция активации: ReLU  \n",
    "Размер входных данных: (150, 150, 3) (высота, ширина, каналы)  \n",
    "Слой пулинга (MaxPooling2D):  \n",
    "Размер пулинга: (2, 2)  \n",
    "По умолчанию используется максимальное значение в каждом окне пулинга.  \n",
    "Свёрточный слой (Conv2D):  \n",
    "Количество фильтров: 64  \n",
    "Размер ядра: (3, 3)  \n",
    "Функция активации: ReLU  \n",
    "Слой пулинга (MaxPooling2D):  \n",
    "Размер пулинга: (2, 2)  \n",
    "Свёрточный слой (Conv2D):  \n",
    "Количество фильтров: 128  \n",
    "Размер ядра: (3, 3)  \n",
    "Функция активации: ReLU  \n",
    "Слой пулинга (MaxPooling2D):   \n",
    "Размер пулинга: (2, 2)  \n",
    "Слой сглаживания (Flatten):  \n",
    "Преобразует многомерные данные в одномерный массив для подачи на полносвязные слои.  \n",
    "Полносвязный слой (Dense):  \n",
    "Количество нейронов: 512  \n",
    "Функция активации: ReLU  \n",
    "Слой Dropout:  \n",
    "Слой Dropout с вероятностью 0.5 помогает предотвратить переобучение, случайным образом \"выключая\" половину нейронов на каждой итерации обучения.  \n",
    "Выходной полносвязный слой (Dense):  \n",
    "Количество нейронов: num_classes (количество классов в задаче классификации)  \n",
    "Функция активации: softmax (используется для многоклассовой классификации)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14488\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# Создаем последовательную модель\n",
    "model = Sequential()\n",
    "\n",
    "# Добавляем сверточные слои с пулингом\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(300, 300, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Добавляем слой для сглаживания данных перед подачей на полносвязные слои\n",
    "model.add(Flatten())\n",
    "\n",
    "# Добавляем полносвязные слои\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Добавляем слой Dropout для уменьшения переобучения\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Выходной слой с softmax для классификации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\14488\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 2s/step - accuracy: 0.1698 - loss: 2.9720 - val_accuracy: 0.2336 - val_loss: 2.1376\n",
      "Epoch 2/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 2s/step - accuracy: 0.2523 - loss: 2.1343 - val_accuracy: 0.2671 - val_loss: 2.0762\n",
      "Epoch 4/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 5/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m343s\u001b[0m 2s/step - accuracy: 0.2738 - loss: 2.0701 - val_accuracy: 0.3172 - val_loss: 2.0161\n",
      "Epoch 6/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 7/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 2s/step - accuracy: 0.2961 - loss: 2.0408 - val_accuracy: 0.3320 - val_loss: 1.9968\n",
      "Epoch 8/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n",
      "Epoch 9/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 2s/step - accuracy: 0.3056 - loss: 2.0171 - val_accuracy: 0.3005 - val_loss: 1.9887\n",
      "Epoch 10/10\n",
      "\u001b[1m194/194\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.0000e+00 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 - 30s - 619ms/step - accuracy: 0.3218 - loss: 1.9754\n",
      "Потери на тестовых данных: 1.9753581285476685\n",
      "Точность на тестовых данных: 0.32175031304359436\n"
     ]
    }
   ],
   "source": [
    "# Оценка производительности модели на тестовых данных:\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, verbose=2)\n",
    "print(f'Потери на тестовых данных: {test_loss}')\n",
    "print(f'Точность на тестовых данных: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
